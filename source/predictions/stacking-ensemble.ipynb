{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://mlfromscratch.com/model-stacking-explained/#/\n",
    "#https://machinelearningmastery.com/super-learner-ensemble-in-python/\n",
    "#https://machinelearningmastery.com/stacking-ensemble-machine-learning-with-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os \n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy import sparse\n",
    "import ast\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot  as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "import keras\n",
    "from keras import Sequential\n",
    "from keras import layers, models, optimizers\n",
    "from keras.layers import Input, Dense, AlphaDropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import text, sequence\n",
    "\n",
    "from sklearn import model_selection, preprocessing, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import pickle\n",
    "import textblob, string\n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import data_lake_helper as dl_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lake = dl_helper.DataLake(version='v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df_to_prepare, key='text_normalized'):\n",
    "    train_x = df_to_prepare[key].tolist()\n",
    "    train_y = df_to_prepare.category.tolist()\n",
    "    return (train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_feature(feature, load_version=None):\n",
    "\n",
    "    if load_version is None:\n",
    "        data_lake_ = data_lake\n",
    "    else:\n",
    "        data_lake_ = DataLake(version=load_version)\n",
    "    \n",
    "    df[feature] = data_lake_.load_obj(feature + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_lake.load_obj('df-cleaned.pkl')\n",
    "\n",
    "f_name = 'text_normalized'\n",
    "load_feature(f_name)\n",
    "\n",
    "df_train_table = df[df.path == 'dataset/train_set/']\n",
    "df_test_table = df[df.path == 'dataset/test_set/']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = prepare_data(df_train_table)\n",
    "valid_x, valid_y = prepare_data(df_test_table)\n",
    "\n",
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelBinarizer()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_types = sorted(df.category.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing feature that we wont't use anymore\n",
    "#del df[f_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LINE_BREAK = '\\n'\n",
    "class BLCounter(TransformerMixin, BaseEstimator):\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, texts):\n",
    "        return [[text.count(LINE_BREAK)] for text in texts]\n",
    "\n",
    "class TextCuter(TransformerMixin, BaseEstimator):\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, texts):\n",
    "        return [text[:15000] for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureUnion(transformer_list=[('c_vect',\n",
       "                                Pipeline(steps=[('TC', TextCuter()),\n",
       "                                                ('CV',\n",
       "                                                 CountVectorizer(max_features=50000,\n",
       "                                                                 ngram_range=[1,\n",
       "                                                                              3],\n",
       "                                                                 stop_words='english')),\n",
       "                                                ('SS',\n",
       "                                                 StandardScaler(with_mean=False))])),\n",
       "                               ('len',\n",
       "                                Pipeline(steps=[('BC', BLCounter()),\n",
       "                                                ('SS', StandardScaler())]))])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params = data_lake.load_config('snn_config.txt')\n",
    "\n",
    "snn_vectorizer = FeatureUnion([\n",
    "  (\"c_vect\", Pipeline([\n",
    "       (\"TC\", TextCuter()),\n",
    "       (\"CV\", CountVectorizer(ngram_range=model_params['ngram_range'], \n",
    "                              max_features=model_params['max_features'],\n",
    "                              stop_words=model_params['letters_language'])),\n",
    "       (\"SS\", StandardScaler(with_mean=False))])),\n",
    "  (\"len\", Pipeline([(\"BC\", BLCounter()), (\"SS\", StandardScaler())]))])\n",
    "\n",
    "train_x = snn_vectorizer.fit_transform(df_train_table[f_name])\n",
    "valid_x = snn_vectorizer.transform(df_test_table[f_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading already trained SNN\n",
    "pipeline = data_lake.load_obj('snn_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SNNtransformer(TransformerMixin, BaseEstimator):\n",
    "    \n",
    "    _estimator_type = \"classifier\"\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def predict(self, texts):\n",
    "        texts_t = snn_vectorizer.transform(texts)\n",
    "\n",
    "        score = pipeline.predict(texts_t).argmax(axis=-1)\n",
    "        encoder = preprocessing.LabelBinarizer()\n",
    "        score_bin = encoder.fit_transform(score)\n",
    "        \n",
    "        return score_bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn_model_pipeline = make_pipeline(SNNtransformer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15059588299024917\n"
     ]
    }
   ],
   "source": [
    "snn_predictions = snn_model_pipeline.transform(df_test_table[f_name])\n",
    "snn_accuracy = metrics.accuracy_score(snn_predictions, valid_y)\n",
    "print(snn_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_features=5000, token_pattern='\\\\w{1,}')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "config = data_lake.load_config('tf_idf_word_vect_config.txt')\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer=config['analyzer'],\n",
    "                             token_pattern=config['token_pattern'],\n",
    "                             max_features=config['max_features'])\n",
    "tfidf_vect.fit(df[f_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfIdfMapper(TransformerMixin, BaseEstimator):\n",
    "    \n",
    "    #https://github.com/scikit-learn/scikit-learn/issues/17597\n",
    "    n_features_in_ = None\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, texts):\n",
    "        return tfidf_vect.transform(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfmapper', TfIdfMapper()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rforest_pipeline = make_pipeline(TfIdfMapper(), ensemble.RandomForestClassifier())\n",
    "rforest_pipeline.fit(df_train_table[f_name], train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9014084507042254\n"
     ]
    }
   ],
   "source": [
    "predictions = rforest_pipeline.predict(df_test_table[f_name])\n",
    "accuracy = metrics.accuracy_score(predictions, valid_y)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "    # define the base models\n",
    "    level0 = list()\n",
    "    level0.append(('rforest_pipeline', rforest_pipeline))\n",
    "    level0.append(('snn_model_pipeline', snn_model_pipeline))\n",
    "\n",
    "    # define meta learner model\n",
    "    level1 = LogisticRegression()\n",
    "\n",
    "    # define the stacking ensemble\n",
    "    model = ensemble.StackingClassifier(estimators=level0, final_estimator=level1, cv=2)#5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(cv=2,\n",
       "                   estimators=[('rforest_pipeline',\n",
       "                                Pipeline(steps=[('tfidfmapper', TfIdfMapper()),\n",
       "                                                ('randomforestclassifier',\n",
       "                                                 RandomForestClassifier())])),\n",
       "                               ('snn_model_pipeline',\n",
       "                                Pipeline(steps=[('snntransformer',\n",
       "                                                 SNNtransformer())]))],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack = get_stacking()\n",
    "stack.fit(df_train_table[f_name][:1000], df_train_table.category[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.856988082340195\n"
     ]
    }
   ],
   "source": [
    "stack_predictions = stack.predict(df_test_table[f_name])\n",
    "accuracy = metrics.accuracy_score(stack_predictions, df_test_table.category)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
